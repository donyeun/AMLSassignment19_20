{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Machine Learning Systems ELEC0134 (19/20) Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "\n",
    "0. Setting Up Environment\n",
    "1. Exploratory Data Analysis\n",
    "2. TASK A1: Gender Detection (Male/Female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setting Up Environment\n",
    "\n",
    "Please set this variable to FALSE if you wanted to retrain the model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (0.25.3)\n",
      "Requirement already satisfied: numpy==1.17.4 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.17.4)\n",
      "Requirement already satisfied: matplotlib==3.1.1 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.1.1)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (4.1.2.30)\n",
      "Requirement already satisfied: Pillow==6.2.1 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (6.2.1)\n",
      "Requirement already satisfied: scikit_learn==0.21.3 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (0.21.3)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (0.16.2)\n",
      "Requirement already satisfied: tqdm==4.39.0 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (4.39.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/site-packages (from pandas==0.25.3->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==0.25.3->-r requirements.txt (line 1)) (2019.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib==3.1.1->-r requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib==3.1.1->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib==3.1.1->-r requirements.txt (line 3)) (2.4.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/site-packages (from scikit_learn==0.21.3->-r requirements.txt (line 6)) (1.3.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit_learn==0.21.3->-r requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/site-packages (from scikit-image->-r requirements.txt (line 7)) (2.4)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/site-packages (from scikit-image->-r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/site-packages (from scikit-image->-r requirements.txt (line 7)) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas==0.25.3->-r requirements.txt (line 1)) (1.13.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib==3.1.1->-r requirements.txt (line 3)) (41.6.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->-r requirements.txt (line 7)) (4.4.1)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some general constants that will be used in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "from imutils import face_utils\n",
    "from PIL import Image\n",
    "from skimage import color, feature, io\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "TEST_DATASET_SIZE_PROPORTION = 0.2\n",
    "K_CROSSVAL = 2\n",
    "CSV_LABEL_SEPARATOR_MARK = '\\t'\n",
    "\n",
    "# TASK A\n",
    "TASK_A_DATASET_DIR = 'Datasets/celeba/img/'\n",
    "TASK_A_LABEL_CSV_FILEPATH = 'Datasets/celeba/labels.csv'\n",
    "TASK_A_X_HEADER_NAME = 'img_name'\n",
    "TASK_A1_Y_HEADER_NAME = 'gender'\n",
    "TASK_A2_Y_HEADER_NAME = 'smiling'\n",
    "TASK_A1_FACE_OUTPUT_DIR  = 'Datasets/processed/celeba_cropped_face/' \n",
    "TASK_A2_MOUTH_OUTPUT_DIR = 'Datasets/processed/celeba_cropped_mouth/'\n",
    "\n",
    "# TASK B\n",
    "TASK_B_DATASET_DIR = 'Datasets/cartoon_set/img/'\n",
    "TASK_B_LABEL_CSV_FILEPATH = 'Datasets/cartoon_set/labels.csv'\n",
    "TASK_B_X_HEADER_NAME = 'file_name'\n",
    "TASK_B1_Y_HEADER_NAME = 'face_shape'\n",
    "TASK_B2_Y_HEADER_NAME = 'eye_color'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis\n",
    "\n",
    "Firstly, let's take a look at characteristics of our dataset. We'll look at the proportion of each label in our dataset, the pixel dimension of image datasets, and to see if whether we should do some additional preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Proportion of Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1. Task A1: Gender Detection using Celeba Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    2500\n",
      " 1    2500\n",
      "Name: gender, dtype: int64\n",
      "[[<matplotlib.axes._subplots.AxesSubplot object at 0x1248fe3d0>]]\n"
     ]
    }
   ],
   "source": [
    "task_a_label_df = pd.read_csv(\n",
    "                    TASK_A_LABEL_CSV_FILEPATH,\n",
    "                    sep=CSV_LABEL_SEPARATOR_MARK\n",
    "                )\n",
    "print(task_a_label_df[TASK_A1_Y_HEADER_NAME].value_counts())\n",
    "print(task_a_label_df.hist(column=TASK_A1_Y_HEADER_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### 1.1.2. Task A2: Emotion Detection (smiling or not) using Celeba Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    2500\n",
      " 1    2500\n",
      "Name: smiling, dtype: int64\n",
      "[[<matplotlib.axes._subplots.AxesSubplot object at 0x108a4cc90>]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAWYUlEQVR4nO3df7DldX3f8efLRXHKWnYRs0FgZG1X041MidwijZnmrqawMBPBqbHLEF38MWtS6MSJnXHRyWg1TDEjcQY1xk2kYCTeIOqwBSyzrmytM0GBlLD8KHJBrGzJbnFxdZVQwXf/ON9bT9b765x77lnWz/Mxc+Z+z+fz+X6/7+/n3Ps6537Pr1QVkqQ2POdwFyBJGh9DX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+NIAkX0qyuVu+KMnX+voOJnnp4atOWthRh7sA6UhSVefM07dynLVIw/CRviQ1xNBXM5K8O8meJD9I8kCS1yZ5f5LPJflM1747ycuSXJpkX5LvJDmrbxu7krx9ju1Xkn/aLV+d5ONJbuq2+/Uk/6Rv7FldDQeS/EmS/zbXdqVRMvTVhCQvBy4B/kVVvQA4G3ik6/5N4C+A1cD/AG6h97dxIvAB4JND7nYT8B+77U4Dl3W1HA9cD1wKvBB4APjVIfchDcTQVyueAY4G1id5blU9UlUPdX3/vapuqaqngc8BLwIur6ofA1PAKUlWDbHPL1bVN7rtXguc1rWfC9xbVV/o+q4E/m4JxyYtmqGvJlTVNPBO4P3AviRTSV7cde/tG/ok8HhVPdN3HWCYJ2n7g/xHfdt4MfCdvtoKeHSI7UsDM/TVjKr6y6r6NeAlQAEfOkylPAacNHMlSfqvS8vJ0FcTkrw8yWuSHA38Pb1H8D85TOXcBJya5PwkRwEXA794mGpRYwx9teJo4HLgcXqnXX6B3hOpY1dVjwO/BfwR8F1gPXAH8NThqEdtiV+iIh1eSZ5D75z+hVV16+GuRz/ffKQvHQZJzk6yqjvd9B4gwG2HuSw1wNCXDo9/CTxE73TTbwLnV9WT868iLZ2ndySpIT7Sl6SGPKs/ZfP444+vU045Zej1f/jDH3LMMceMrqARsa7BWNdgrGswP4913XnnnY9X1Ytm7ayqZ+3l9NNPr6W49dZbl7T+crGuwVjXYKxrMD+PdQF31By56ukdSWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1JAFQz/JyUluTXJfknuT/F7X/v7u+0bv6i7n9q1zaZLp7jtAz+5r39i1TSfZujyHJEmay2LenPU08K6q+pskLwDuTLKj6/tIVX24f3CS9fS+G/SX6X1D0JeTvKzr/jjwr+l9ouDtSbZX1X2jOBBJ0sIWDP2qeozeN/1QVT9Icj+9L4yey3nAVFU9BXwryTRwRtc3XVUPAySZ6sYa+pI0JgN94FqSU4CvAq8Afh+4CPg+vS+AeFdVPZHkY8BtVfWZbp1PAV/qNrGxqt7etb8JeFVVXXLIPrYAWwDWrFlz+tTU1LDHxr79B9h7GD638NQTj523/+DBg6xcOcxXri4v6xqMdQ3mSK1r954DY6zmp9Yeu2Lo+dqwYcOdVTUxW9+iP3snyUrg88A7q+r7ST4BfJDed41+ELgCeOtQFfapqm3ANoCJiYmanJwcelsfvfYGrtg9/o8XeuTCyXn7d+3axVKOa7lY12CsazBHal0Xbb1pfMX0uXrjMcsyX4tKxCTPpRf411bVFwCqam9f/58BN3ZX9wAn961+UtfGPO2SpDFYzKt3AnwKuL+q/riv/YS+Ya8H7umWtwObkhydZC2wDvgGcDuwLsnaJM+j92Tv9tEchiRpMRbzSP/VwJuA3Unu6treA1yQ5DR6p3ceAd4BUFX3JrmO3hO0TwMXV9UzAEkuAW4BVgBXVdW9IzwWSdICFvPqna/R+/7OQ908zzqXAZfN0n7zfOtJkpaX78iVpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNWTB0E9ycpJbk9yX5N4kv9e1H5dkR5IHu5+ru/YkuTLJdJK7k7yyb1ubu/EPJtm8fIclSZrNYh7pPw28q6rWA2cCFydZD2wFdlbVOmBndx3gHGBdd9kCfAJ6dxLA+4BXAWcA75u5o5AkjceCoV9Vj1XV33TLPwDuB04EzgOu6YZdA5zfLZ8HfLp6bgNWJTkBOBvYUVX7q+oJYAewcaRHI0maV6pq8YOTU4CvAq8A/ldVreraAzxRVauS3AhcXlVf6/p2Au8GJoHnV9Ufdu1/ADxZVR8+ZB9b6P2HwJo1a06fmpoa+uD27T/A3ieHXn1op5547Lz9Bw8eZOXKlWOqZvGsazDWNZgjta7dew6MsZqfWnvsiqHna8OGDXdW1cRsfUctdiNJVgKfB95ZVd/v5XxPVVWSxd97zKOqtgHbACYmJmpycnLobX302hu4YveiD3FkHrlwct7+Xbt2sZTjWi7WNRjrGsyRWtdFW28aXzF9rt54zLLM16JevZPkufQC/9qq+kLXvLc7bUP3c1/Xvgc4uW/1k7q2udolSWOymFfvBPgUcH9V/XFf13Zg5hU4m4Eb+trf3L2K50zgQFU9BtwCnJVkdfcE7lldmyRpTBZz7uPVwJuA3Unu6treA1wOXJfkbcC3gTd2fTcD5wLTwI+AtwBU1f4kHwRu78Z9oKr2j+QoJEmLsmDod0/IZo7u184yvoCL59jWVcBVgxQoSRod35ErSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JasiCoZ/kqiT7ktzT1/b+JHuS3NVdzu3ruzTJdJIHkpzd176xa5tOsnX0hyJJWshiHulfDWycpf0jVXVad7kZIMl6YBPwy906f5JkRZIVwMeBc4D1wAXdWEnSGB210ICq+mqSUxa5vfOAqap6CvhWkmngjK5vuqoeBkgy1Y29b+CKJUlDW8o5/UuS3N2d/lndtZ0IfKdvzKNd21ztkqQxSlUtPKj3SP/GqnpFd30N8DhQwAeBE6rqrUk+BtxWVZ/pxn0K+FK3mY1V9fau/U3Aq6rqkln2tQXYArBmzZrTp6amhj64ffsPsPfJoVcf2qknHjtv/8GDB1m5cuWYqlk86xqMdQ3mSK1r954DY6zmp9Yeu2Lo+dqwYcOdVTUxW9+Cp3dmU1V7Z5aT/BlwY3d1D3By39CTujbmaT9029uAbQATExM1OTk5TIkAfPTaG7hi91CHuCSPXDg5b/+uXbtYynEtF+sajHUN5kit66KtN42vmD5XbzxmWeZrqNM7SU7ou/p6YOaVPduBTUmOTrIWWAd8A7gdWJdkbZLn0Xuyd/vwZUuShrHgw+AknwUmgeOTPAq8D5hMchq90zuPAO8AqKp7k1xH7wnap4GLq+qZbjuXALcAK4CrqurekR+NJGlei3n1zgWzNH9qnvGXAZfN0n4zcPNA1UmSRsp35EpSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMWDP0kVyXZl+SevrbjkuxI8mD3c3XXniRXJplOcneSV/ats7kb/2CSzctzOJKk+Szmkf7VwMZD2rYCO6tqHbCzuw5wDrCuu2wBPgG9OwngfcCrgDOA983cUUiSxmfB0K+qrwL7D2k+D7imW74GOL+v/dPVcxuwKskJwNnAjqraX1VPADv42TsSSdIyS1UtPCg5Bbixql7RXf9eVa3qlgM8UVWrktwIXF5VX+v6dgLvBiaB51fVH3btfwA8WVUfnmVfW+j9l8CaNWtOn5qaGvrg9u0/wN4nh159aKeeeOy8/QcPHmTlypVjqmbxrGsw1jWYI7Wu3XsOjLGan1p77Iqh52vDhg13VtXEbH1HLakqoKoqycL3HIvf3jZgG8DExERNTk4Ova2PXnsDV+xe8iEO7JELJ+ft37VrF0s5ruViXYOxrsEcqXVdtPWm8RXT5+qNxyzLfA376p293Wkbup/7uvY9wMl9407q2uZqlySN0bChvx2YeQXOZuCGvvY3d6/iORM4UFWPAbcAZyVZ3T2Be1bXJkkaowXPfST5LL1z8scneZTeq3AuB65L8jbg28Abu+E3A+cC08CPgLcAVNX+JB8Ebu/GfaCqDn1yWJK0zBYM/aq6YI6u184ytoCL59jOVcBVA1UnSRop35ErSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JasiSQj/JI0l2J7kryR1d23FJdiR5sPu5umtPkiuTTCe5O8krR3EAkqTFG8Uj/Q1VdVpVTXTXtwI7q2odsLO7DnAOsK67bAE+MYJ9S5IGsBynd84DrumWrwHO72v/dPXcBqxKcsIy7F+SNIdU1fArJ98CngAK+GRVbUvyvapa1fUHeKKqViW5Ebi8qr7W9e0E3l1VdxyyzS30/hNgzZo1p09NTQ1d3779B9j75NCrD+3UE4+dt//gwYOsXLlyTNUsnnUNxroGc6TWtXvPgTFW81Nrj10x9Hxt2LDhzr6zL//AUUuqCn6tqvYk+QVgR5L/2d9ZVZVkoHuVqtoGbAOYmJioycnJoYv76LU3cMXupR7i4B65cHLe/l27drGU41ou1jUY6xrMkVrXRVtvGl8xfa7eeMyyzNeSTu9U1Z7u5z7gi8AZwN6Z0zbdz33d8D3AyX2rn9S1SZLGZOjQT3JMkhfMLANnAfcA24HN3bDNwA3d8nbgzd2reM4EDlTVY0NXLkka2FLOfawBvtg7bc9RwF9W1X9NcjtwXZK3Ad8G3tiNvxk4F5gGfgS8ZQn7liQNYejQr6qHgX8+S/t3gdfO0l7AxcPuT5K0dL4jV5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGjL20E+yMckDSaaTbB33/iWpZWMN/SQrgI8D5wDrgQuSrB9nDZLUsnE/0j8DmK6qh6vq/wJTwHljrkGSmnXUmPd3IvCdvuuPAq/qH5BkC7Clu3owyQNL2N/xwONLWH8o+dCCQw5LXYtgXYOxrsFY1wA2fGhJdb1kro5xh/6CqmobsG0U20pyR1VNjGJbo2Rdg7GuwVjXYFqra9ynd/YAJ/ddP6lrkySNwbhD/3ZgXZK1SZ4HbAK2j7kGSWrWWE/vVNXTSS4BbgFWAFdV1b3LuMuRnCZaBtY1GOsajHUNpqm6UlXLsV1J0rOQ78iVpIYY+pLUkCM+9JP8VpJ7k/wkyZwvb5rr4x+6J5W/3rX/VfcE8yjqOi7JjiQPdj9XzzJmQ5K7+i5/n+T8ru/qJN/q6zttXHV1457p2/f2vvbDOV+nJfnr7va+O8m/7esb2Xwt9FEhSY7ujn26m4tT+vou7dofSHL2sDUMWdfvJ7mvm5udSV7S1zfr7TnG2i5K8n/6anh7X9/m7nZ/MMnmMdb0kb56vpnke319yzZfSa5Ksi/JPXP0J8mVXd13J3llX9/S56qqjugL8M+AlwO7gIk5xqwAHgJeCjwP+Ftgfdd3HbCpW/5T4HdHVNcfAVu75a3AhxYYfxywH/hH3fWrgTcsw3wtqi7g4Bzth22+gJcB67rlFwOPAatGOV/z/a70jfl3wJ92y5uAv+qW13fjjwbWdttZMaL5WUxdG/p+f353pq75bs8x1nYR8LFZ1j0OeLj7ubpbXj2Omg4Z/+/pvbBkHPP1r4BXAvfM0X8u8CUgwJnA10c5V0f8I/2qur+qFnrX7qwf/5AkwGuA67tx1wDnj6i087rtLXa7bwC+VFU/GtH+5zJoXf/f4Z6vqvpmVT3YLf9vYB/wohHtf8ZiPiqkv9brgdd2c3MeMFVVT1XVt4Dpbntjqauqbu37/bmN3vtgxmEpH69yNrCjqvZX1RPADmDjYajpAuCzI9jvgqrqq/Qe4M3lPODT1XMbsCrJCYxoro740F+k2T7+4UTghcD3qurpQ9pHYU1VPdYt/x2wZoHxm/jZX7rLun/vPpLk6DHX9fwkdyS5beaUE8+i+UpyBr1HcA/1NY9ivub6XZl1TDcXB+jNzWLWHdag234bvUeLM2a7PUdlsbX9m+72uT7JzJs0l2vOFr3d7jTYWuArfc3LOV8Lmav2kczVs+5jGGaT5MvAL87S9d6qumHc9cyYr67+K1VVSeZ8bWx3L34qvfcvzLiUXvg9j97rdd8NfGCMdb2kqvYkeSnwlSS76YXb0EY8X38BbK6qn3TNQ8/Xz5skvw1MAL/e1/wzt2dVPTT7FpbFfwE+W1VPJXkHvf+UXjPG/c9nE3B9VT3T13a452vZHBGhX1W/scRNzPXxD9+l96/TUd0jtoE+FmK+upLsTXJCVT3WhdS+eTb1RuCLVfXjvm3PPOp9Ksl/Bv7DOOuqqj3dz4eT7AJ+Bfg8h3m+kvxj4CZ6d/i39W176Pk6xGI+KmRmzKNJjgKOpfe7tJwfM7KobSf5DXp3or9eVU/NtM9xe44qxBasraq+23f1z+k9hzOz7uQh6+4aR019NgEX9zcs83wtZK7aRzJXrZzemfXjH6r37Mit9M6nA2wGRvWfw/Zue4vZ7s+cT+yCb+Y8+vnArM/0L0ddSVbPnB5JcjzwauC+wz1f3W33RXrnO68/pG9U87WYjwrpr/UNwFe6udkObErv1T1rgXXAN4asY+C6kvwK8EngdVW1r6991ttzRHUttrYT+q6+Dri/W74FOKurcTVwFv/wP95lq6mr65foPSn6131tyz1fC9kOvLl7Fc+ZwIHuQc1o5mq5nqEe1wV4Pb1zW08Be4FbuvYXAzf3jTsX+Ca9e+v39rW/lN4f5jTwOeDoEdX1QmAn8CDwZeC4rn0C+PO+cafQuwd/ziHrfwXYTS+8PgOsHFddwK92+/7b7ufbng3zBfw28GPgrr7LaaOer9l+V+idKnpdt/z87tinu7l4ad+67+3WewA4Z8S/6wvV9eXub2BmbrYvdHuOsbb/BNzb1XAr8Et96761m8tp4C3jqqm7/n7g8kPWW9b5ovcA77Hud/lRes+//A7wO11/6H3Z1EPd/if61l3yXPkxDJLUkFZO70iSMPQlqSmGviQ1xNCXpIYY+pLUEENfkhpi6EtSQ/4fu0J6xM8h8eEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(task_a_label_df[TASK_A2_Y_HEADER_NAME].value_counts())\n",
    "print(task_a_label_df.hist(column=TASK_A2_Y_HEADER_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### 1.1.3. Task B1: Face Shape Recognition using Cartoonset Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    2000\n",
      "3    2000\n",
      "2    2000\n",
      "1    2000\n",
      "0    2000\n",
      "Name: face_shape, dtype: int64\n",
      "[[<matplotlib.axes._subplots.AxesSubplot object at 0x124f67a50>]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_b_label_df = pd.read_csv(\n",
    "                    TASK_B_LABEL_CSV_FILEPATH,\n",
    "                    sep=CSV_LABEL_SEPARATOR_MARK\n",
    "                )\n",
    "print(task_b_label_df[TASK_B1_Y_HEADER_NAME].value_counts())\n",
    "print(task_b_label_df.hist(column=TASK_B1_Y_HEADER_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### 1.1.4. Task B2: Eye Colour Recognition using Cartoonset Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2018\n",
      "4    2017\n",
      "0    2004\n",
      "3    1992\n",
      "2    1969\n",
      "Name: eye_color, dtype: int64\n",
      "[[<matplotlib.axes._subplots.AxesSubplot object at 0x125714c90>]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAbn0lEQVR4nO3df5RcZZ3n8feHgJiTdhIUpickwcSzwR0gYyS9yB5XT/WiENAh6rpuWAaIPya64ihnco4ExxlYkXPYXaMuMIMTIScwRFoG1GRCGCYiPQx7NmDCIB1AJEg4ps0mo4GOLTnMBL77Rz09lE11V9W9XdVJns/rnDpd9TzPvc/3eerWt27dul1XEYGZmeXhqMkOwMzMOsdJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMuKkb9ZBkiqSdk12HJYvJ30zs4w46ZsdJiRNmewY7PDnpG9HFEknSrpL0j9JelbSZyX9jqQXJb2ppt3pqc0x6fHHJD0p6XlJ90p6cxN9nSpps6R9kvZI+kIqP1bS1yX9PN2+LunYMdbxu5L6Jb0g6XFJ59fUrZV0o6RNkn4N9JaeIMuek74dMSQdBfwN8CNgFnAWcBnwNqAf+EhN84uAvoj4F0lLgC8AHwJOAP4BuL1BX28Avg/8LXAi8G+A+1L1nwBnAgtT32cAX6yzjmNSvH8H/DbwR8A6SW+tafZfgWuANwAPNp4Fs/HJv71jRwpJ7wD+OiJOqim7AjiZanL+bES8Mx0mGQTOj4iHJd0D3BkRN6dljgKGgd+NiOfG6OsC4PMR8fY6dc8AfxQRm9Ljc4C/jIi5kirAbRExW9K7gL8GToyIV1Lb24GnIuIqSWuBoyLi4gmYHjPAe/p2ZHkzcGI6VPKCpBeo7sF3A+uBUyTNA94LDEXEwzXL/e+aZfYBovppYSxzgGfGqDsRqH2zeC6V1Wv3s5GEX9O2tt+fjRODWcuOnuwAzCbQz4BnI2J+vUpJdwB/APxb4K9GLXdNRKxrsa+lY9T9nOobyePp8UmprF67OZKOqkn8JwE/qWnjj+I2obynb0eSh4FfSbpc0lRJUySdJunfpfpbgWXA+fxm0v8GcIWkUwEkTZf0nxv0tRGYKemy9MXtG9LhJah+H/BFSSdIOh74M+C2Out4CHgR+LykY9Khn98H+loduFmznPTtiBERLwPvp/oF6rPAL4CbgOmp/v8ArwCP1B6rj4jvAv8D6JO0H9gOnNugr19RPUz0+8D/A57m1bNrvgxsBR4DBoBHUtnodfxzWv7cFOtfABdHxI9bH71Zc/xFrmVF0g+Ab0XETZMdi9lkcNK3bKTDPJuBOWlP3Sw7PrxjWZB0C9Xz6i9rNuFLepek4Xq39kZr1j7e0zczy4j39M3MMnLIn6d//PHHx9y5cwst++tf/5pp06ZNbEATwHG1xnG1xnG15kiMa9u2bb+IiBPqVkbEIX1btGhRFHX//fcXXradHFdrHFdrHFdrjsS4gK0xRk714R0zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMtIw6UuaI+l+SU+kCzd/LpW/MV0U+un097hULknXSdoh6TFJp9es65LU/mlJl7RvWGZmVk8ze/oHgRURcQrViz1fKukUYCVwX1SvUnRfegzV3wafn27LgRuh+iYBXAm8g+qFoq8ceaMwM7POaPgzDBGxG9id7v9K0pNUr+G5BKikZrcA/cDlqfzW9F9hWyTNkDQztd0cEfsAJG0GFlO9ypBNkLkr7y687IoFB1lWcPmd176vcL9mh7Iyr6ky1i5uz09DtPTbO5LmAm+nepm37vSGANUrB3Wn+7P4zYs570plY5W3zcDgUOEkVoYToJkdqpr+aWVJXcDfU72A9HckvRARM2rqn4+I4yRtBK6NiAdT+X1UPwFUgNdHxJdT+Z8CByLiK3X6Wk710BDd3d2L+vqKXTJ0774h9hwotGgpC2ZNH7d+eHiYrq6utvQ9MDhUeNnuqRSer0ZjLqOd81VGjnHluH2VGXMZ86ZPKfw89vb2bouInnp1Te3pSzoGuAtYFxHfScV7JM2MiN3p8M3eVD4IzKlZfHYqG+TVw0Ej5f31+ouI1cBqgJ6enqhUKvWaNXT9uvWsGuj8D4nuvLAybn1/fz9Fx9RImU82KxYcLDxfjcZcRjvnq4wc48px+5qMowVQPbzTjuexmbN3BNwMPBkRX62p2gCMnIFzCbC+pvzidBbPmcBQOgx0L3C2pOPSF7hnpzIzM+uQZt523wlcBAxIejSVfQG4FrhD0seB54CPpLpNwHnADuBF4KMAEbFP0tXAD1O7L418qWt2OPJ3RnY4aubsnQcBjVF9Vp32AVw6xrrWAGtaCdDMzCaO/yPXzCwjTvpmZhlx0jczy4iTvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMuKkb2aWESd9M7OMOOmbmWXESd/MLCPNXCN3jaS9krbXlH1b0qPptnPkMoqS5ko6UFP3jZplFkkakLRD0nXp2rtmZtZBzVwjdy1wA3DrSEFE/JeR+5JWAUM17Z+JiIV11nMj8IfAQ1Svo7sYuKf1kM3MrKiGe/oR8QBQ9wLmaW/9I8Dt461D0kzgtyJiS7qG7q3AB1oP18zMylA1BzdoJM0FNkbEaaPK3w18NSJ6ato9DvwE2A98MSL+QVIPcG1EvCe1exdweUS8f4z+lgPLAbq7uxf19fUVGRt79w2x50ChRUtZMGv6uPXDw8N0dXW1pe+BwaHGjcbQPZXC89VozGW0c77K8PbVmsN1+yoz5jLmTZ9S+Hns7e3dNpKXR2vm8M54LuA39/J3AydFxC8lLQK+J+nUVlcaEauB1QA9PT1RqVQKBXf9uvWsGig7xNbtvLAybn1/fz9Fx9TIspV3F152xYKDheer0ZjLaOd8leHtqzWH6/ZVZsxlrF08rS3PY+EtVtLRwIeARSNlEfES8FK6v03SM8DJwCAwu2bx2anMzMw6qMwpm+8BfhwRu0YKJJ0gaUq6/xZgPvDTiNgN7Jd0Zvoe4GJgfYm+zcysgGZO2bwd+L/AWyXtkvTxVLWU136B+27gsXQK553ApyJi5EvgTwM3ATuAZ/CZO2ZmHdfw8E5EXDBG+bI6ZXcBd43RfitwWr06MzPrDP9HrplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMuKkb2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLiJO+mVlGmrlc4hpJeyVtrym7StKgpEfT7byauisk7ZD0lKRzasoXp7IdklZO/FDMzKyRZvb01wKL65R/LSIWptsmAEmnUL127qlpmb+QNCVdLP3PgXOBU4ALUlszM+ugZq6R+4CkuU2ubwnQFxEvAc9K2gGckep2RMRPAST1pbZPtByxmZkVpoho3Kia9DdGxGnp8VXAMmA/sBVYERHPS7oB2BIRt6V2NwP3pNUsjohPpPKLgHdExGfG6G85sBygu7t7UV9fX6HB7d03xJ4DhRYtZcGs6ePWDw8P09XV1Za+BwaHCi/bPZXC89VozGW0c77K8PbVmsN1+yoz5jLmTZ9S+Hns7e3dFhE99eoa7umP4UbgaiDS31XAxwqu6zUiYjWwGqCnpycqlUqh9Vy/bj2rBooOsbidF1bGre/v76fomBpZtvLuwsuuWHCw8Hw1GnMZ7ZyvMrx9teZw3b7KjLmMtYunteV5LPQMRMSekfuSvglsTA8HgTk1TWenMsYpNzOzDil0yqakmTUPPwiMnNmzAVgq6VhJ84D5wMPAD4H5kuZJeh3VL3s3FA/bzMyKaLinL+l2oAIcL2kXcCVQkbSQ6uGdncAnASLicUl3UP2C9iBwaUS8nNbzGeBeYAqwJiIen/DRmJnZuJo5e+eCOsU3j9P+GuCaOuWbgE0tRWdmZhPK/5FrZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMuKkb2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLiJO+mVlGnPTNzDLSMOlLWiNpr6TtNWX/S9KPJT0m6buSZqTyuZIOSHo03b5Rs8wiSQOSdki6TpLaMyQzMxtLM3v6a4HFo8o2A6dFxO8BPwGuqKl7JiIWptunaspvBP6Q6nVz59dZp5mZtVnDpB8RDwD7RpX9XUQcTA+3ALPHW0e6kPpvRcSWiAjgVuADxUI2M7OiJuKY/seAe2oez5P0j5L+XtK7UtksYFdNm12pzMzMOkjVHe8GjaS5wMaIOG1U+Z8APcCHIiIkHQt0RcQvJS0CvgecCpwMXBsR70nLvQu4PCLeP0Z/y4HlAN3d3Yv6+voKDW7vviH2HCi0aCkLZk0ft354eJiurq629D0wOFR42e6pFJ6vRmMuo53zVYa3r9YcrttXmTGXMW/6lMLPY29v77aI6KlXd3TRgCQtA94PnJUO2RARLwEvpfvbJD1DNeEP8puHgGansroiYjWwGqCnpycqlUqhGK9ft55VA4WHWNjOCyvj1vf391N0TI0sW3l34WVXLDhYeL4ajbmMds5XGd6+WnO4bl9lxlzG2sXT2vI8Fjq8I2kx8Hng/Ih4sab8BElT0v23UP3C9qcRsRvYL+nMdNbOxcD60tGbmVlLGr7tSrodqADHS9oFXEn1bJ1jgc3pzMst6UyddwNfkvQvwCvApyJi5EvgT1M9E2gq1e8Aar8HMDOzDmiY9CPigjrFN4/R9i7grjHqtgKn1aszM7PO8H/kmpllxEnfzCwjTvpmZhlx0jczy4iTvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMuKkb2aWESd9M7OMOOmbmWWkqaQvaY2kvZK215S9UdJmSU+nv8elckm6TtIOSY9JOr1mmUtS+6clXTLxwzEzs/E0u6e/Flg8qmwlcF9EzAfuS48BzqV6QfT5wHLgRqi+SVC9vu47gDOAK0feKMzMrDOaSvoR8QCwb1TxEuCWdP8W4AM15bdG1RZghqSZwDnA5ojYFxHPA5t57RuJmZm1kSKiuYbSXGBjRJyWHr8QETPSfQHPR8QMSRuBayPiwVR3H3A5UAFeHxFfTuV/ChyIiK/U6Ws51U8JdHd3L+rr6ys0uL37hthzoNCipSyYNX3c+uHhYbq6utrS98DgUOFlu6dSeL4ajbmMds5XGd6+WnO4bl9lxlzGvOlTCj+Pvb292yKip17d0aWiSiIiJDX37tHc+lYDqwF6enqiUqkUWs/169azamBChtiSnRdWxq3v7++n6JgaWbby7sLLrlhwsPB8NRpzGe2crzK8fbXmcN2+yoy5jLWLp7XleSxz9s6edNiG9HdvKh8E5tS0m53Kxio3M7MOKZP0NwAjZ+BcAqyvKb84ncVzJjAUEbuBe4GzJR2XvsA9O5WZmVmHNPVZS9LtVI/JHy9pF9WzcK4F7pD0ceA54COp+SbgPGAH8CLwUYCI2CfpauCHqd2XImL0l8NmZtZGTSX9iLhgjKqz6rQN4NIx1rMGWNN0dGZmNqH8H7lmZhlx0jczy4iTvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMuKkb2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGSmc9CW9VdKjNbf9ki6TdJWkwZry82qWuULSDklPSTpnYoZgZmbNaupyifVExFPAQgBJU4BB4LtUr4n7tYj4Sm17SacAS4FTgROB70s6OSJeLhqDmZm1ZqIO75wFPBMRz43TZgnQFxEvRcSzVC+cfsYE9W9mZk1Q9TrmJVcirQEeiYgbJF0FLAP2A1uBFRHxvKQbgC0RcVta5mbgnoi4s876lgPLAbq7uxf19fUVimvvviH2HCi0aCkLZk0ft354eJiurq629D0wOFR42e6pFJ6vRmMuo53zVYa3r9YcrttXmTGXMW/6lMLPY29v77aI6KlXVzrpS3od8HPg1IjYI6kb+AUQwNXAzIj4WCtJv1ZPT09s3bq1UGzXr1vPqoHCR7AK23nt+8at7+/vp1KptKXvuSvvLrzsigUHC89XozGX0c75KsPbV2sO1+2rzJjLWLt4WuHnUdKYSX8iDu+cS3Uvfw9AROyJiJcj4hXgm7x6CGcQmFOz3OxUZmZmHTIRSf8C4PaRB5Jm1tR9ENie7m8Alko6VtI8YD7w8AT0b2ZmTSr12VTSNOC9wCdriv+npIVUD+/sHKmLiMcl3QE8ARwELvWZO2ZmnVUq6UfEr4E3jSq7aJz21wDXlOnTzMyK83/kmpllxEnfzCwjTvpmZhlx0jczy4iTvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMuKkb2aWESd9M7OMlE76knZKGpD0qKStqeyNkjZLejr9PS6VS9J1knZIekzS6WX7NzOz5k3Unn5vRCysufr6SuC+iJgP3JceQ/Ui6vPTbTlw4wT1b2ZmTWjX4Z0lwC3p/i3AB2rKb42qLcCMURdSNzOzNlJElFuB9CzwPNULof9lRKyW9EJEzEj1Ap6PiBmSNgLXRsSDqe4+4PKI2DpqncupfhKgu7t7UV9fX6HY9u4bYs+BoiMrbsGs6ePWDw8P09XV1Za+BwaHCi/bPZXC89VozGW0c77K8PbVmsN1+yoz5jLmTZ9S+Hns7e3dVnPk5TeUujB68h8iYlDSbwObJf24tjIiQlJL7ywRsRpYDdDT0xOVSqVQYNevW8+qgYkYYmt2XlgZt76/v5+iY2pk2cq7Cy+7YsHBwvPVaMxltHO+yvD21ZrDdfsqM+Yy1i6e1pbnsfThnYgYTH/3At8FzgD2jBy2SX/3puaDwJyaxWenMjMz64BSSV/SNElvGLkPnA1sBzYAl6RmlwDr0/0NwMXpLJ4zgaGI2F0mBjMza17Zz6bdwHerh+05GvhWRPytpB8Cd0j6OPAc8JHUfhNwHrADeBH4aMn+zcysBaWSfkT8FHhbnfJfAmfVKQ/g0jJ9mplZcf6PXDOzjDjpm5llxEnfzCwjTvpmZhlx0jczy4iTvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMuKkb2aWESd9M7OMFE76kuZIul/SE5Iel/S5VH6VpEFJj6bbeTXLXCFph6SnJJ0zEQMwM7Pmlblc4kFgRUQ8ki6Ovk3S5lT3tYj4Sm1jSacAS4FTgROB70s6OSJeLhGDmZm1oPCefkTsjohH0v1fAU8Cs8ZZZAnQFxEvRcSzVC+OfkbR/s3MrHWqXqu85EqkucADwGnAHwPLgP3AVqqfBp6XdAOwJSJuS8vcDNwTEXfWWd9yYDlAd3f3or6+vkJx7d03xJ4DhRYtZcGs6ePWDw8P09XV1Za+BwaHCi/bPZXC89VozGW0c77K8PbVmsN1+yoz5jLmTZ9S+Hns7e3dFhE99erKHN4BQFIXcBdwWUTsl3QjcDUQ6e8q4GOtrDMiVgOrAXp6eqJSqRSK7fp161k1UHqILdt5YWXc+v7+foqOqZFlK+8uvOyKBQcLz1ejMZfRzvkqw9tXaw7X7avMmMtYu3haW57HUmfvSDqGasJfFxHfAYiIPRHxckS8AnyTVw/hDAJzahafncrMzKxDypy9I+Bm4MmI+GpN+cyaZh8Etqf7G4Clko6VNA+YDzxctH8zM2tdmc+m7wQuAgYkPZrKvgBcIGkh1cM7O4FPAkTE45LuAJ6geubPpT5zx8ysswon/Yh4EFCdqk3jLHMNcE3RPs3MrBz/R66ZWUac9M3MMuKkb2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLiJO+mVlGnPTNzDLipG9mlhEnfTOzjDjpm5llxEnfzCwjTvpmZhlx0jczy4iTvplZRjqe9CUtlvSUpB2SVna6fzOznHU06UuaAvw5cC5wCtXr6Z7SyRjMzHLW6T39M4AdEfHTiPhnoA9Y0uEYzMyypYjoXGfSh4HFEfGJ9Pgi4B0R8ZlR7ZYDy9PDtwJPFezyeOAXBZdtJ8fVGsfVGsfVmiMxrjdHxAn1Ko4uHk/7RMRqYHXZ9UjaGhE9ExDShHJcrXFcrXFcrcktrk4f3hkE5tQ8np3KzMysAzqd9H8IzJc0T9LrgKXAhg7HYGaWrY4e3omIg5I+A9wLTAHWRMTjbeyy9CGiNnFcrXFcrXFcrckqro5+kWtmZpPL/5FrZpYRJ30zs4wcEUm/0U87SDpW0rdT/UOS5h4icS2T9E+SHk23T3QgpjWS9kraPka9JF2XYn5M0untjqnJuCqShmrm6s86FNccSfdLekLS45I+V6dNx+esybg6PmeSXi/pYUk/SnH99zptOv56bDKujr8ea/qeIukfJW2sUzex8xURh/WN6hfCzwBvAV4H/Ag4ZVSbTwPfSPeXAt8+ROJaBtzQ4fl6N3A6sH2M+vOAewABZwIPHSJxVYCNk7B9zQROT/ffAPykzvPY8TlrMq6Oz1mag650/xjgIeDMUW0m4/XYTFwdfz3W9P3HwLfqPV8TPV9Hwp5+Mz/tsAS4Jd2/EzhLkg6BuDouIh4A9o3TZAlwa1RtAWZImnkIxDUpImJ3RDyS7v8KeBKYNapZx+esybg6Ls3BcHp4TLqNPluk46/HJuOaFJJmA+8DbhqjyYTO15GQ9GcBP6t5vIvXbvz/2iYiDgJDwJsOgbgA/lM6JHCnpDl16jut2bgnw79PH8/vkXRqpztPH6vfTnUvsdakztk4ccEkzFk6VPEosBfYHBFjzlcHX4/NxAWT83r8OvB54JUx6id0vo6EpH84+xtgbkT8HrCZV9/N7bUeofp7Im8Drge+18nOJXUBdwGXRcT+TvY9ngZxTcqcRcTLEbGQ6n/cnyHptE7020gTcXX89Sjp/cDeiNjW7r5GHAlJv5mfdvjXNpKOBqYDv5zsuCLilxHxUnp4E7CozTE145D8qYyI2D/y8TwiNgHHSDq+E31LOoZqYl0XEd+p02RS5qxRXJM5Z6nPF4D7gcWjqibj9dgwrkl6Pb4TOF/STqqHgP+jpNtGtZnQ+ToSkn4zP+2wAbgk3f8w8INI34pMZlyjjvueT/W47GTbAFyczkg5ExiKiN2THZSk3xk5jinpDKrbbtsTRerzZuDJiPjqGM06PmfNxDUZcybpBEkz0v2pwHuBH49q1vHXYzNxTcbrMSKuiIjZETGXao74QUT8wahmEzpfh+SvbLYixvhpB0lfArZGxAaqL46/krSD6peFSw+RuD4r6XzgYIprWbvjknQ71bM6jpe0C7iS6pdaRMQ3gE1Uz0bZAbwIfLTdMTUZ14eB/ybpIHAAWNqBN26o7oldBAyk48EAXwBOqoltMuasmbgmY85mAreoesGko4A7ImLjZL8em4yr46/HsbRzvvwzDGZmGTkSDu+YmVmTnPTNzDLipG9mlhEnfTOzjDjpm5llxEnfzCwjTvpmZhn5/8oHzMQbWzVLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(task_b_label_df[TASK_B2_Y_HEADER_NAME].value_counts())\n",
    "print(task_b_label_df.hist(column=TASK_B2_Y_HEADER_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Now, let's look at the dimension of each image in our two datasets, to see if whether we should do preprocessing to make the image size uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Pixel Dimension of Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. Task A Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pixel_size_in_dataset(dataset_foldername, filename_list):\n",
    "    pixel_size_list = []\n",
    "    for filename in filename_list:\n",
    "        filepath = os.path.join(dataset_foldername, filename)\n",
    "        width, height = Image.open(filepath).size\n",
    "        pixel_size_list.append(str(width) + \", \" + str(height))\n",
    "    pixel_size_df = pd.DataFrame(pixel_size_list, columns=['img_dimension'])\n",
    "    print(pixel_size_df['img_dimension'].value_counts())\n",
    "    return pixel_size_df['img_dimension'].value_counts(), pixel_size_df['img_dimension'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178, 218    5000\n",
      "Name: img_dimension, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(178, 218    5000\n",
       " Name: img_dimension, dtype: int64,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x125998550>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_a_img_filename_list = task_a_label_df[TASK_A_X_HEADER_NAME]\n",
    "check_pixel_size_in_dataset(TASK_A_DATASET_DIR, task_a_img_filename_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. Task B Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500, 500    10000\n",
      "Name: img_dimension, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 500    10000\n",
       " Name: img_dimension, dtype: int64,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x125971b10>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_b_img_filename_list = task_b_label_df[TASK_B_X_HEADER_NAME]\n",
    "check_pixel_size_in_dataset(TASK_B_DATASET_DIR, task_b_img_filename_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1.3. Conclusion from Exploratory Data Analysis\n",
    "From the exploratory data analysis, we learn that the ratio/proportion of each label in dataset is already good, so we don't need to preprocess the dataset to even out the ratio.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TASK A1: Gender Detection (Male/Female)\n",
    "\n",
    "In this binary classification task, we are going to use the `celeba` dataset to detect gender from the face image dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load the Dataset\n",
    "\n",
    "Firstly we wanted to load the dataset. Separating training and testing dataset will be done in later process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_X_and_Y_set_from_label_file(label_csv_filepath, x_header_name, y_header_name, delimiter=CSV_LABEL_SEPARATOR_MARK):\n",
    "    \"\"\"Determine the X (the input features) and the Y (label) from a CSV file\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(label_csv_filepath) as csv_file:\n",
    "        data = csv.DictReader(csv_file, delimiter=delimiter)\n",
    "        for row in data:\n",
    "            X.append(row[x_header_name])\n",
    "            Y.append(row[y_header_name])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = determine_X_and_Y_set_from_label_file(\n",
    "    TASK_A_LABEL_CSV_FILEPATH,\n",
    "    TASK_A_X_HEADER_NAME,\n",
    "    TASK_A1_Y_HEADER_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Cropping the Person's Face from the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_face_detector(input_dir, img_filename, face_detector, output_dir):\n",
    "    \"\"\"Detect face using HOG\n",
    "    \"\"\"\n",
    "    img_filepath = os.path.join(input_dir, img_filename)\n",
    "    img = cv2.imread(img_filepath)\n",
    "    \n",
    "    rects = face_detector(img, 1)\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "        cropped_img = img[\n",
    "            y:y+h,\n",
    "            x:x+w,\n",
    "        ]\n",
    "\n",
    "        cv2.imwrite(os.path.join(output_dir, img_filename), cropped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5000/5000 [01:57<00:00, 42.44it/s]\n"
     ]
    }
   ],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "for X_filename in tqdm(X):\n",
    "    hog_face_detector(\n",
    "        input_dir = TASK_A_DATASET_DIR,\n",
    "        img_filename = X_filename,\n",
    "        face_detector = face_detector,\n",
    "        output_dir = TASK_A1_FACE_OUTPUT_DIR,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Divide into Training and Testing Dataset\n",
    "\n",
    "There will be some images where the mouth is undetected. In this case, we are unable to use that particular image.\n",
    "After deciding which of data can be used, we are then going to divide the dataset into either training or testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data :  3864\n",
      "testing data  :  967\n"
     ]
    }
   ],
   "source": [
    "cropped_img_filenames = os.listdir(TASK_A1_FACE_OUTPUT_DIR)\n",
    "\n",
    "X_cropped = []\n",
    "Y_cropped = []\n",
    "for ori_img_filename in X:\n",
    "    if ori_img_filename in cropped_img_filenames:\n",
    "        X_cropped.append(ori_img_filename)\n",
    "        row_num = X.index(ori_img_filename)\n",
    "        Y_cropped.append(Y[row_num])\n",
    "\n",
    "X_train_filenames, X_test_filenames, Y_train, Y_test = train_test_split(\n",
    "    X_cropped, Y_cropped, test_size=TEST_DATASET_SIZE_PROPORTION, random_state=42,\n",
    ")\n",
    "\n",
    "print(\"training data : \", len(X_train_filenames))\n",
    "print(\"testing data  : \", len(X_test_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Local Binary Pattern (LBP) + Histogram\n",
    "\n",
    "As part of the feature engineering, we are going to convert raw images into greyscale. The next process is to determine the LBP. After that, the final step is to output the resulted histogram. This (standardised, which will be done later) histogram is going to be the feature that will be used to be fitted into training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_raw_images_to_lbp_histograms(image_dir, image_filenames, lbp_params):\n",
    "    \"\"\"Extract LBP histograms from raw images \n",
    "    \"\"\"\n",
    "    hists = []\n",
    "    for filename in tqdm(image_filenames):\n",
    "        filepath = os.path.join(image_dir, filename)\n",
    "\n",
    "        # load the image file\n",
    "        image = io.imread(filepath)\n",
    "\n",
    "        # convert RGB image into greyscale\n",
    "        grey_image = color.rgb2grey(image)\n",
    "\n",
    "        # convert greyscale image into lbp features\n",
    "        lbp_image = feature.local_binary_pattern(\n",
    "            grey_image,\n",
    "            lbp_params['n_points'],\n",
    "            lbp_params['radius'],\n",
    "            lbp_params['method'],\n",
    "        )\n",
    "\n",
    "        # convert lbp features into histogram\n",
    "        n_bins = int(lbp_image.max() + 1)\n",
    "        hist, _ = np.histogram(\n",
    "            lbp_image.ravel(),\n",
    "            bins=n_bins,\n",
    "            range=(0, n_bins)\n",
    "        )\n",
    "        hists.append(hist)\n",
    "    return hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3864/3864 [00:13<00:00, 286.11it/s]\n"
     ]
    }
   ],
   "source": [
    "LBP_PARAMS = {\n",
    "    'n_points': 8,\n",
    "    'radius'  : 1,\n",
    "    'method'  : 'default',\n",
    "#     'method'  : 'uniform',\n",
    "#     'method'  : 'ror',\n",
    "}\n",
    "    \n",
    "X_train_hists = convert_raw_images_to_lbp_histograms(\n",
    "    TASK_A1_FACE_OUTPUT_DIR,\n",
    "    X_train_filenames,\n",
    "    LBP_PARAMS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. SVM Classifier Parameter Tuning\n",
    "The next thing to do is to use the histogram features and fit it into an SVM classifier.<br>\n",
    "We are going to use grid search and k-fold cross validation, which is `GridSearchCV` function in Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVM (and save the resulted model afterwards to a local pickle file)\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:  7.6min remaining:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed: 20.8min finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# if local model exists, use them instead of retraining it\n",
    "# otherwise, train the SVM model with gridsearch+k-fold CV\n",
    "try:\n",
    "    TASK_A1_MODELS_PKL_FILEPATH = 'models/task_a1_dec_15_v2.pkl'\n",
    "    clf = pickle.load(\n",
    "        open(TASK_A1_MODELS_PKL_FILEPATH, \"rb\")\n",
    "    )\n",
    "    print(\"local model is found and being used instead of retraining the model\")\n",
    "except (OSError, IOError) as e:\n",
    "    print(\"training SVM (and save the resulted model afterwards to a local pickle file)\")\n",
    "    # SVM hyperparameter tuning\n",
    "#     svm_param_candidates = [\n",
    "# #         {\n",
    "# #             'kernel': ['rbf'],\n",
    "# #             'gamma' : [1e-3, 1e-4],\n",
    "# #     #         'C'     : [1],\n",
    "# #             'C'     : [1, 10, 100, 1000]\n",
    "# #         },\n",
    "#         {\n",
    "#             'kernel': ['linear'],\n",
    "#             'C'     : [1],\n",
    "# #             'C'     : [1, 10, 100, 1000]\n",
    "#         }\n",
    "#     ]\n",
    "    svm_param_candidates = [\n",
    "        {\n",
    "            'C'     : [1, 10, 100],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Do grid search and k-cross validation to SVM Classifier\n",
    "    \n",
    "    clf = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        GridSearchCV(\n",
    "            LinearSVC(max_iter=1000000),\n",
    "#             SVC(),\n",
    "            svm_param_candidates,\n",
    "            cv = K_CROSSVAL,\n",
    "            iid = False, # suggested value from sklearn\n",
    "            n_jobs = -1,\n",
    "            verbose = 4,\n",
    "        ),\n",
    "    )\n",
    "#     clf = GridSearchCV(\n",
    "# #         LinearSVC(),\n",
    "#         SVC(),\n",
    "#         svm_param_candidates,\n",
    "#         cv = K_CROSSVAL,\n",
    "#         iid = False, # suggested value from sklearn\n",
    "#         n_jobs = -1,\n",
    "#         verbose = 4,\n",
    "#     )\n",
    "#     from sklearn.svm import LinearSVC\n",
    "#     clf = LinearSVC(random_state=0, tol=1e-5, C=10, verbose=True, max_iter=10000)\n",
    "#     from sklearn import preprocessing\n",
    "    # # buang\n",
    "#     X_train_hists = X_train_hists[:250]\n",
    "#     Y_train = Y_train[:250]\n",
    "    clf.fit(X_train_hists, Y_train)\n",
    "    \n",
    "    # save all the models resulted to a local pickle\n",
    "    pickle.dump(\n",
    "        clf,\n",
    "        open(TASK_A1_MODELS_PKL_FILEPATH, \"wb\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1994c93dfb4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Best parameters and best result on development set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best params : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean        : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stdev       : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'params      : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "# Best parameters and best result on development set\n",
    "print('best params : ', clf.best_params_)\n",
    "print('mean        : ', clf.cv_results_['mean_test_score'])\n",
    "print('stdev       : ', clf.cv_results_['std_test_score'])\n",
    "print('params      : ', clf.cv_results_['params'])\n",
    "print('best estimator: ', clf.best_estimator_)\n",
    "\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Inference\n",
    "\n",
    "Now that the training process is done and we have the model, we will see the accuracy score of this selected model by using testing dataset that the model has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 967/967 [00:03<00:00, 287.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc score  0.766287487073423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_hists = convert_raw_images_to_lbp_histograms(\n",
    "    TASK_A1_FACE_OUTPUT_DIR,\n",
    "    X_test_filenames,\n",
    "    LBP_PARAMS,\n",
    ")\n",
    "\n",
    "\n",
    "Y_pred = clf.predict(X_test_hists)\n",
    "print(\"acc score \", accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TASK A2: Emotion Detection (Smiling/Not Smiling)\n",
    "\n",
    "In this binary classification task, we are going to use the `celeba` dataset again to detect whether the person on the photo is smiling or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Load the Dataset\n",
    "\n",
    "Firstly we wanted to load the dataset. Separating training and testing dataset will be done in later process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = determine_X_and_Y_set_from_label_file(\n",
    "    TASK_A_LABEL_CSV_FILEPATH,\n",
    "    TASK_A_X_HEADER_NAME,\n",
    "    TASK_A2_Y_HEADER_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Cropping the Person's Lip from the Image\n",
    "\n",
    "We are going to crop the lip/mouth from the image, using the Haar Cascade. The cropped image will be saved in a dedicated folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$$$WAIT, coba pikirin ulang tentang reusing pickle filenya, soalnya\n",
    "kan ntar jadi ada data testing yg muncul lagi (karena train/test splitting)\n",
    "\n",
    "harus ditulis bahwa for the purpose of presentation alias\n",
    "feasibility to present the result in short time (without having to wait\n",
    "        hours and hours, we're going to use pickle and train/test split yg ga random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haar_cascade_object_cropping(input_dir, img_filename, haar_cascade_filepath, scale_factor, min_neighbors, output_dir):\n",
    "    \"\"\"Detect object that matters using Haar Cascade, crop the image, then save the cropped image to a local folder\n",
    "    \"\"\"\n",
    "    img_filepath = os.path.join(input_dir, img_filename)\n",
    "    right_eye_cascade = cv2.CascadeClassifier(haar_cascade_filepath)\n",
    "    img = cv2.imread(img_filepath)\n",
    "#     $$$# https://stackoverflow.com/questions/20801015/recommended-values-for-opencv-detectmultiscale-parameters\n",
    "    obj = right_eye_cascade.detectMultiScale(img, scale_factor, min_neighbors)\n",
    "    for (x, y, w, h) in obj:\n",
    "        cropped_img = img[y:y+h, x:x+w]\n",
    "        cropped_img = cv2.resize(cropped_img, dsize=(42, 26))\n",
    "#         cropped_img = cropped_img.resize((42,26), Image.ANTIALIAS)\n",
    "        cv2.imwrite(os.path.join(output_dir, img_filename), cropped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5000/5000 [01:41<00:00, 49.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# haarcascade_mouth_filepath = 'haarcascades/haarcascade_mcs_mouth.xml'\n",
    "\n",
    "# scale_factor = 1.7\n",
    "# min_neighbors = 3\n",
    "\n",
    "# for X_filename in tqdm(X):\n",
    "#     haar_cascade_object_cropping(\n",
    "#         input_dir = TASK_A_DATASET_DIR,\n",
    "#         img_filename = X_filename,\n",
    "#         haar_cascade_filepath = haarcascade_mouth_filepath,\n",
    "#         scale_factor = scale_factor,\n",
    "#         min_neighbors = min_neighbors,\n",
    "#         output_dir = TASK_A2_MOUTH_OUTPUT_DIR,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_mouth_detector(input_dir, img_filename, face_detector, shape_predictor, output_dir):\n",
    "    \"\"\"Detect mouth using HOG\n",
    "    \"\"\"  \n",
    "    # https://www.pyimagesearch.com/2017/04/10/detect-eyes-nose-lips-jaw-dlib-opencv-python/\n",
    "    mouth_point_start = 48\n",
    "    mouth_point_end = 68\n",
    "    \n",
    "    img_filepath = os.path.join(input_dir, img_filename)\n",
    "    img = cv2.imread(img_filepath)\n",
    "    \n",
    "    rects = face_detector(img, 1)\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = shape_predictor(img, rect)\n",
    "        \n",
    "        mouth_x_points = [shape.part(nth_point).x for nth_point in range(mouth_point_start, mouth_point_end)]\n",
    "        mouth_y_points = [shape.part(nth_point).y for nth_point in range(mouth_point_start, mouth_point_end)]\n",
    "\n",
    "        max_x = max(mouth_x_points)\n",
    "        min_x = min(mouth_x_points)\n",
    "        max_y = max(mouth_y_points)\n",
    "        min_y = min(mouth_y_points)\n",
    "        extra = 3\n",
    "\n",
    "        cropped_img = img[\n",
    "                min_y - extra:max_y + extra,\n",
    "                min_x - extra:max_x + extra,\n",
    "        ]\n",
    "\n",
    "#         cropped_img = cv2.resize(cropped_img, dsize=(42, 26))\n",
    "#         cropped_img = cropped_img.resize((42,26), Image.ANTIALIAS)\n",
    "        cv2.imwrite(os.path.join(output_dir, img_filename), cropped_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hog_mouth_detector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ff8212da3ce4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     hog_mouth_detector(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0minput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTASK_A_DATASET_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimg_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hog_mouth_detector' is not defined"
     ]
    }
   ],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "SHAPE_PREDICTOR_68_FACE_LANDMARKS_FILEPATH = \"models/shape_predictor_68_face_landmarks.dat\"\n",
    "shape_predictor = dlib.shape_predictor(SHAPE_PREDICTOR_68_FACE_LANDMARKS_FILEPATH)\n",
    "\n",
    "for X_filename in tqdm(X):\n",
    "    hog_mouth_detector(\n",
    "        input_dir = TASK_A_DATASET_DIR,\n",
    "        img_filename = X_filename,\n",
    "        face_detector = face_detector,\n",
    "        shape_predictor = shape_predictor,\n",
    "        output_dir = TASK_A2_MOUTH_OUTPUT_DIR,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Divide into Training and Testing Dataset\n",
    "\n",
    "There will be some images where the mouth is undetected. In this case, we are unable to use that particular image.<br>\n",
    "\n",
    "After deciding which of data can be used, we are then going to divide the dataset into either training or testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data :  3864\n",
      "testing data  :  967\n"
     ]
    }
   ],
   "source": [
    "cropped_img_filenames = os.listdir(TASK_A2_MOUTH_OUTPUT_DIR)\n",
    "\n",
    "X_cropped = []\n",
    "Y_cropped = []\n",
    "for ori_img_filename in X:\n",
    "    if ori_img_filename in cropped_img_filenames:\n",
    "        X_cropped.append(ori_img_filename)\n",
    "        row_num = X.index(ori_img_filename)\n",
    "        Y_cropped.append(Y[row_num])\n",
    "\n",
    "X_train_filenames, X_test_filenames, Y_train, Y_test = train_test_split(\n",
    "    X_cropped, Y_cropped, test_size=TEST_DATASET_SIZE_PROPORTION, random_state=42,\n",
    ")\n",
    "\n",
    "print(\"training data : \", len(X_train_filenames))\n",
    "print(\"testing data  : \", len(X_test_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Local Binary Pattern (LBP) + Histogram\n",
    "\n",
    "As part of the feature engineering, we are going to convert raw images into greyscale. The next process is to determine the LBP. After that, the final step is to output the resulted histogram. This (standardised, which will be done later) histogram is going to be the feature that will be used to be fitted into training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3864/3864 [00:06<00:00, 564.07it/s]\n"
     ]
    }
   ],
   "source": [
    "LBP_PARAMS = {\n",
    "    'n_points': 8,\n",
    "    'radius'  : 1,\n",
    "    'method'  : 'default',\n",
    "#     'method'  : 'uniform',\n",
    "#     'method'  : 'ror',\n",
    "}\n",
    "    \n",
    "X_train_hists = convert_raw_images_to_lbp_histograms(\n",
    "    TASK_A2_MOUTH_OUTPUT_DIR,\n",
    "    X_train_filenames,\n",
    "    LBP_PARAMS,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. SVM Classifier Parameter Tuning\n",
    "The next thing to do is to use the histogram features and fit it into an SVM classifier.<br>\n",
    "We are going to use grid search and k-fold cross validation, which is `GridSearchCV` function in Scikit Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVM (and save the resulted model afterwards to a local pickle file)\n",
      "Fitting 3 folds for each of 43 candidates, totalling 129 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "exception calling callback for <Future at 0x12a9d72d0 state=finished raised TerminatedWorkerError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 340, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 768, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 834, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 753, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 543, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\", line 160, in submit\n",
      "    fn, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 1027, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6)}\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-c18df46a88a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     clf = pickle.load(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTASK_A2_MODELS_PKL_FILEPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/task_a2_dec_15_v20.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-c18df46a88a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m     )\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_hists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;31m#     scaler = StandardScaler()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#     X_train_hists = scaler.fit_transform(X_train_hists)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/externals/loky/_base.py\u001b[0m in \u001b[0;36m_invoke_callbacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exception calling callback for %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \"\"\"\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSafeFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_future_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             return super(_ReusablePoolExecutor, self).submit(\n\u001b[0;32m--> 160\u001b[0;31m                 fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                 raise ShutdownExecutorError(\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGABRT(-6), SIGABRT(-6), SIGABRT(-6), SIGABRT(-6)}"
     ]
    }
   ],
   "source": [
    "# if local model exists, use them instead of retraining it\n",
    "# otherwise, train the SVM model with gridsearch+k-fold CV\n",
    "try:\n",
    "    TASK_A2_MODELS_PKL_FILEPATH = 'models/task_a2_dec_15_v20.pkl'\n",
    "    clf = pickle.load(\n",
    "        open(TASK_A2_MODELS_PKL_FILEPATH, \"rb\")\n",
    "    )\n",
    "    print(\"local model is found and being used instead of retraining the model\")\n",
    "except (OSError, IOError) as e:\n",
    "    print(\"training SVM (and save the resulted model afterwards to a local pickle file)\")\n",
    "    # SVM hyperparameter tuning\n",
    "    svm_param_candidates = [\n",
    "            {\n",
    "                'kernel': ['rbf'],\n",
    "                'gamma' : [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                'C'     : [0.1, 1, 10, 100]\n",
    "            },\n",
    "            {\n",
    "                'kernel': ['linear'],\n",
    "                'C'     : [1, 10, 100],\n",
    "            },\n",
    "            {\n",
    "                'kernel': ['poly'],\n",
    "                'degree': [3],\n",
    "                'gamma' : [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                'C'     : [0.1, 1, 10, 100]\n",
    "            },\n",
    "        ]\n",
    "\n",
    "#     svm_param_candidates = [\n",
    "#         {\n",
    "#             'C'     : [1, 10, 100],\n",
    "#         },\n",
    "#     ]\n",
    "    \n",
    "    # Do grid search and k-cross validation to SVM Classifier\n",
    "#     clf = make_pipeline(\n",
    "#         StandardScaler(),\n",
    "#         GridSearchCV(\n",
    "#             LinearSVC(),\n",
    "#             svm_param_candidates,\n",
    "#             cv = K_CROSSVAL,\n",
    "#             iid = False, # suggested value from sklearn\n",
    "#             n_jobs = -1,\n",
    "#             verbose = 4,\n",
    "#         ),\n",
    "#     )\n",
    "#     from sklearn import preprocessing\n",
    "#     clf = LinearSVC(random_state=0, tol=1e-5, C=1, verbose=True, max_iter=1000000)\n",
    "        \n",
    "    clf = GridSearchCV(\n",
    "        SVC(),\n",
    "        svm_param_candidates,\n",
    "        cv = K_CROSSVAL,\n",
    "        iid = False, # suggested value from sklearn\n",
    "        n_jobs = -1,\n",
    "        verbose = 4,\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train_hists[:200], Y_train[:200])\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train_hists = scaler.fit_transform(X_train_hists)\n",
    "\n",
    "    # numerical stability\n",
    "#     X_train_hists = preprocessing.scale(X_train_hists)\n",
    "#     clf.fit(X_train_hists, Y_train)\n",
    "\n",
    "    \n",
    "    # save all the models resulted to a local pickle\n",
    "    pickle.dump(\n",
    "        clf,\n",
    "        open(TASK_A2_MODELS_PKL_FILEPATH, \"wb\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-1994c93dfb4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Best parameters and best result on development set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best params : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean        : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stdev       : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'params      : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "# Best parameters and best result on development set\n",
    "print('best params : ', clf.best_params_)\n",
    "print('mean        : ', clf.cv_results_['mean_test_score'])\n",
    "print('stdev       : ', clf.cv_results_['std_test_score'])\n",
    "print('params      : ', clf.cv_results_['params'])\n",
    "print('best estimat: ', clf.best_estimator_)\n",
    "\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Inference\n",
    "\n",
    "Now that the training process is done and we have the model, we will see the accuracy score of this selected model by using testing dataset that the model has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 967/967 [00:01<00:00, 524.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc score  0.8066184074457083\n"
     ]
    }
   ],
   "source": [
    "X_test_hists = convert_raw_images_to_lbp_histograms(\n",
    "    TASK_A2_MOUTH_OUTPUT_DIR,\n",
    "    X_test_filenames,\n",
    "    LBP_PARAMS,\n",
    ")\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_test_hists = scaler.transform(X_test_hists)\n",
    "# X_test_hists = preprocessing.scale(X_test_hists)\n",
    "Y_pred = clf.predict(X_test_hists)\n",
    "\n",
    "print(\"acc score \", accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
